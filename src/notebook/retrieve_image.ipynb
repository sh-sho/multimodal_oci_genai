{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df15a98f",
   "metadata": {},
   "source": [
    "### Retrieve Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ab2f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_core.documents import Document\n",
    "from langchain.callbacks.manager import CallbackManagerForRetrieverRun\n",
    "from langchain.schema import BaseRetriever\n",
    "from typing import List\n",
    "import oracledb\n",
    "import pandas as pd\n",
    "import base64\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "from langchain_community.embeddings import OCIGenAIEmbeddings\n",
    "from langchain_community.chat_models import ChatOCIGenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "oracledb.init_oracle_client()\n",
    "\n",
    "UN = os.getenv(\"UN\")\n",
    "PW = os.getenv(\"PW\")\n",
    "DSN = os.getenv(\"DSN\")\n",
    "OCI_COMPARTMENT_ID = os.getenv(\"OCI_COMPARTMENT_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a573399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "def get_embedding(text: str) -> list:\n",
    "  embeddings = OCIGenAIEmbeddings(\n",
    "    model_id=\"cohere.embed-multilingual-v3.0\",\n",
    "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n",
    "    compartment_id=OCI_COMPARTMENT_ID,\n",
    "  )\n",
    "  return embeddings.embed_query(text)\n",
    "\n",
    "def chat_with_image(image_path: str, prompt: str, system_prompt: str = None) -> str:\n",
    "  with open(\"/home/opc/multimodal_oci_genai/\" + image_path, \"rb\") as img_file:\n",
    "    image_data = base64.b64encode(img_file.read()).decode(\"utf-8\")\n",
    "  \n",
    "  prompt_with_image = [\n",
    "    SystemMessage(\n",
    "        content=system_prompt\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=[\n",
    "            {\"type\": \"text\", \"text\": prompt},\n",
    "            {\n",
    "              \"type\": \"image_url\",\n",
    "              \"image_url\": {\n",
    "                \"url\": \"data:image/png;base64,\"+image_data,\n",
    "            }\n",
    "        },\n",
    "        ]\n",
    "      )\n",
    "  ]\n",
    "\n",
    "  llm = ChatOCIGenAI(\n",
    "      model_id=\"meta.llama-3.2-90b-vision-instruct\",\n",
    "      service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n",
    "      compartment_id=OCI_COMPARTMENT_ID,\n",
    "      )\n",
    "  result = llm.invoke(prompt_with_image)\n",
    "  print(f\"Result: {result}\") \n",
    "  return result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bf30d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageRetriever(BaseRetriever):\n",
    "    \"\"\"\n",
    "    Custom image retriever.\n",
    "    \"\"\"\n",
    "\n",
    "    def _get_relevant_documents(\n",
    "        self, query: str, *, run_manager: CallbackManagerForRetrieverRun\n",
    "    ) -> List[Document]:\n",
    "        docs: List[Document] = []\n",
    "        embed_query = str(get_embedding(query))\n",
    "        try:\n",
    "            with oracledb.connect(user=UN, password=PW, dsn=DSN) as connection:\n",
    "                with connection.cursor() as cursor:\n",
    "                    cursor.setinputsizes(oracledb.DB_TYPE_VECTOR)\n",
    "                    select_sql = f\"\"\"\n",
    "                        SELECT\n",
    "                            file_id,\n",
    "                            image_path,\n",
    "                            summary\n",
    "                        FROM\n",
    "                            image_contents\n",
    "                        ORDER BY VECTOR_DISTANCE(embedding, to_vector(:1, 1024, FLOAT32), COSINE)\n",
    "                        FETCH FIRST 3 ROWS ONLY\n",
    "                    \"\"\"\n",
    "                    cursor.execute(select_sql, [embed_query])\n",
    "                    index = 1\n",
    "                    for row in cursor:\n",
    "                        doc = Document(\n",
    "                            page_content=row[2],\n",
    "                            metadata={\n",
    "                                'file_id':row[0], \n",
    "                                'file_path': row[1], \n",
    "                                'vector_index': index\n",
    "                                }\n",
    "                            )\n",
    "                        docs.append(doc)\n",
    "                        index += 1\n",
    "                connection.close()\n",
    "                        \n",
    "        except oracledb.DatabaseError as e:\n",
    "            print(f\"Database error: {e}\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            print(\"Error Vector Search:\", e)\n",
    "        \n",
    "        return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c45b07",
   "metadata": {},
   "source": [
    "### Retrieve Image & Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aa5e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_by_image(query: str):\n",
    "    \"\"\"\n",
    "    Text to Image\n",
    "    \"\"\"\n",
    "    llm = ChatOCIGenAI(\n",
    "        model_id=\"cohere.command-r-08-2024\",\n",
    "        service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n",
    "        compartment_id=OCI_COMPARTMENT_ID,\n",
    "        )\n",
    "    \n",
    "    prompt = ChatPromptTemplate([\n",
    "        (\"system\", \"あなたは質疑応答のAIアシスタントです。必ず日本語で答えてください。\"),\n",
    "        (\"human\", \"{query} 以下のコンテキストに基づいて答えてください。{context}\"),\n",
    "    ])\n",
    "\n",
    "    retriever = CustomImageRetriever()\n",
    "    chain = {'query': RunnablePassthrough(), 'context': retriever} | prompt | llm | StrOutputParser()\n",
    "\n",
    "    result_images = chain.invoke(query)\n",
    "    print(result_images)\n",
    "    \n",
    "    file_id = result_images[0].metadata['file_id']\n",
    "    try:\n",
    "        with oracledb.connect(user=UN, password=PW, dsn=DSN) as connection:\n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.setinputsizes(oracledb.DB_TYPE_VECTOR)\n",
    "                select_sql = f\"\"\"\n",
    "                    SELECT\n",
    "                        image_blob\n",
    "                    FROM\n",
    "                        image_contents\n",
    "                    WHERE file_id = :1\n",
    "                \"\"\"\n",
    "                cursor.execute(select_sql, [file_id])\n",
    "                blob, = cursor.fetchone()\n",
    "                offset = 1\n",
    "                bufsize = 65536\n",
    "                with open('tmp_image.png', 'wb') as f:\n",
    "                    while True:\n",
    "                        data = blob.read(offset, bufsize)\n",
    "                        if data:\n",
    "                            f.write(data)\n",
    "                        if len(data) < bufsize:\n",
    "                            break\n",
    "                        offset += bufsize\n",
    "            connection.close()\n",
    "                    \n",
    "    except oracledb.DatabaseError as e:\n",
    "        print(f\"Database error: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(\"Error Vector Search:\", e)\n",
    "    \n",
    "    return result_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8410e45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_by_text_with_image(question: str):\n",
    "    \n",
    "    prompt = ChatPromptTemplate([\n",
    "        (\"system\", \"あなたは言語翻訳のAIアシスタントです。日本語を英語に翻訳してください。\"),\n",
    "        (\"human\", \"{input} \"),\n",
    "    ])\n",
    "    \n",
    "    llm = ChatOCIGenAI(\n",
    "        model_id=\"cohere.command-r-08-2024\",\n",
    "        service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n",
    "        compartment_id=OCI_COMPARTMENT_ID,\n",
    "    )\n",
    "    chain = {'input': RunnablePassthrough()} | prompt | llm | StrOutputParser()\n",
    "    question_en = chain.invoke({\"input\":question})\n",
    "    \n",
    "    retriever = CustomImageRetriever()\n",
    "    result_images = retriever.invoke(question)\n",
    "    print(result_images)\n",
    "    \n",
    "    image_path = result_images[0].metadata['file_path']\n",
    "\n",
    "    res = chat_with_image(\n",
    "        image_path=image_path,\n",
    "        prompt=question_en,\n",
    "        system_prompt=\"You are a AI assistant. Please answer the question based on the image.\"\n",
    "    )\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70a9bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed26a85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddf40ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fe3043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67143a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a79024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86719aef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b2a33b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
